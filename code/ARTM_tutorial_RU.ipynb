{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "ARTM_tutorial_RU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n0DMTHVAeWJ",
        "colab_type": "code",
        "outputId": "33d43ecf-ef2c-4fcd-da53-fee387b729a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install bigartm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bigartm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/8b/e100b260e9ce76c29dfe4837177d1e9a8e15cbdfa03662eb737b0bcfbbce/bigartm-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.0 in /usr/local/lib/python3.6/dist-packages (from bigartm) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bigartm) (4.28.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from bigartm) (0.25.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bigartm) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0->bigartm) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0->bigartm) (45.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->bigartm) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->bigartm) (2.6.1)\n",
            "Installing collected packages: bigartm\n",
            "Successfully installed bigartm-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdXdDxzIA7ex",
        "colab_type": "code",
        "outputId": "61a540d1-4518-4d71-be9e-22103b9e7059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACSqojE2BjoM",
        "colab_type": "code",
        "outputId": "862d82c3-fa88-4bc6-f8d2-7d6a86031b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /gdrive/My\\ Drive/Datasets/r8/lemmatized_wo_stopwords"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.bz2  train.bz2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwAwLCrOGF3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir r8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnd72GMY_XA3",
        "colab_type": "text"
      },
      "source": [
        "# BigARTM. Руководство для пользователей Python API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCIu6j-N_XA6",
        "colab_type": "text"
      },
      "source": [
        "Автор - **Мурат Апишев** (great-mel@yandex.ru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK7eLXMV_XA9",
        "colab_type": "text"
      },
      "source": [
        "Этот ноутбук представляет собой руководство по использованию библиотеки в основных случаях использования. Свои вопросы по случаям, не рассмотренным в данном документе, присылайте в сообщество bigartm-users@googlegroups.com."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inlMVi1v_XA_",
        "colab_type": "text"
      },
      "source": [
        "Предполагается, что Вы в точности выполнили инструкции по установке библиотеки и её настройки для использования из Python (http://bigartm.readthedocs.org/en/master/installation/index.html) и модуль artm у Вас импортируется без ошибок."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTLAwkQc_XBB",
        "colab_type": "text"
      },
      "source": [
        "Итак, импортируем этот модуль:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H1CMW1G_XBD",
        "colab_type": "code",
        "outputId": "0707f97f-de45-48c8-c7ec-23f762984ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import artm\n",
        "\n",
        "print(artm.version())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zi57OeX_XBR",
        "colab_type": "text"
      },
      "source": [
        "Каждый из описанных далее сценариев является отдельным блоком кода, не зависящим от других (за исключением самого первого, про словари и батчи - его надо выполнять всегда). Код рабочий (в том смысле его можно копипастить в свои скрипты), в том случае, если Вы верно подготовите все требуемые данные и разместите их там, где нужно.\n",
        "\n",
        "Прежде, чем задавать вопросы по указанному выше адресу, убедись в том, что он не связан с Вашими некорректными действиями. Одна из наиболее типичных ошибок имеет примерно такой вид:\n",
        "\n",
        "DiskReadException: File vocab.kos.txt does not exist.\n",
        "\n",
        "Скорее всего, она связана с тем, что Вы не подготовили данные, неверно разместили их, либо неверно назвали файл с ними (дважды написали расширение или что-то в этом роде).\n",
        "\n",
        "Также предполагается, что Вы владеете языком Python на достаточном уровне, вопросы по особенностям языка лучше задавать на соответствующих интернет-ресурсах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8A5BkKd_XBT",
        "colab_type": "text"
      },
      "source": [
        "### Словари и батчи в BigARTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQpJNTArIK6P",
        "colab_type": "code",
        "outputId": "98bba9fe-4233-40b7-ff9b-c1a84735d819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import os\n",
        "import bz2\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
            "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
            "  _deprecated()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ShBhbTbZ9mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_vw_format(df, out_file, text_col='text', ngram_col='ngrams', label_col='label'):\n",
        "    '''\n",
        "    Format example: doc_100500 |@default_class aaa:2 bbb:4 ccc ddd:6 |@labels_class class_1 class_6\n",
        "    '''\n",
        "    with open(out_file, 'w') as f:\n",
        "        for index, row in df.iterrows():\n",
        "            line = f'{index} |@default_class {row[text_col]} |@ngrams_class {row[ngram_col]}'\n",
        "            if label_col is not None:\n",
        "                line += f' |@labels_class {row[label_col]}'\n",
        "            f.write(line + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bj_RiM8ggW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bigrams(senntence):\n",
        "    \"\"\"\n",
        "    Фильтруем токены и оставляем только биграммы\n",
        "    \"\"\"\n",
        "    tokens = senntence.split()\n",
        "    tokens_bigrams = bigram[tokens]\n",
        "    return ' '.join([x for x in tokens_bigrams if '_' in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qrqeuI0cyVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def load_and_save_vw(dataset_path):\n",
        "#     with bz2.BZ2File(dataset_path, \"r\") as f:\n",
        "#         df = pd.read_json(f, lines=True)\n",
        "#         to_vw_format(df, os.path.join(dataset, 'train_vw.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWtdMBqq_XBV",
        "colab_type": "text"
      },
      "source": [
        "Прежде, чем приступать непосредственно к моделированию, необходимо привести данные к формату, подходящему для использования библиотекой. Сперва ознакомьтесь с форматами сырых данных, которые можно подавать BigARTM (http://bigartm.readthedocs.org/en/master/formats.html). Задача подготовки файла в одном из таких форматах лежит на Вас. Перевод же этих данных во внутренний формат библиотеки (пакеты документов, именуемы батчами), можно проделать с помощью создания объекта класса BatchVectorizer.\n",
        "\n",
        "Впрочем, есть один более простой вариант обработки Вашей коллекции на тот случай, если она не слишком велика и Вам не нужно сохранять её в батчи. Для этого Вам необходимо получить для своей коллекции переменную n\\_wd типа numpy.ndarray размера \"число уникальных слова в коллекции\" на \"число документов\", содержащую счётчики $n_{wd}$ (т. е. матрицу \"мешка слов\") и Python dict vocabulary в котором ключом является индекс строки этой матрицы, а значением - исходное слово. Получить такие переменные при наличии у Вас сырых текстов проще всего с использованием CountVectorizer (или схожих классов) из sklearn.\n",
        "\n",
        "При наличии этих переменных можно запустить следующий код:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o7kebzvIEb3",
        "colab_type": "text"
      },
      "source": [
        "# Подготовка батчей в памяти"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkfhIknTIPHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = '/gdrive/My Drive/Datasets/'\n",
        "dataset = 'r8'\n",
        "os.makedirs(dataset, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4_tGCzqc-Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.path.join(base_path, dataset, 'lemmatized_wo_stopwords/train.bz2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_hTDT2BIEQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with bz2.BZ2File(os.path.join(base_path, dataset, 'lemmatized_wo_stopwords/train.bz2'), \"r\") as f:\n",
        "    df_train = pd.read_json(f, lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CoZZxWqJPE_",
        "colab_type": "code",
        "outputId": "44f9ed77-ac87-45bd-9d5d-90b0096d98f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>champion product ch approve stock split champi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>computer terminal system cpml complete sale co...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cobanco inc cbco year net shr ct vs dlr net vs...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>international inc nd qtr jan oper shr loss two...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  champion product ch approve stock split champi...      1\n",
              "1  computer terminal system cpml complete sale co...      2\n",
              "2  cobanco inc cbco year net shr ct vs dlr net vs...      1\n",
              "3  international inc nd qtr jan oper shr loss two...      1\n",
              "4  brown forman inc bfd th qtr net shr one dlr vs...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmGl88-IZcFr",
        "colab_type": "code",
        "outputId": "8ffd8afb-8c1b-4c06-9ae5-ebfc2dc545e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "df_train['label'].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.517776\n",
              "2    0.290975\n",
              "6    0.046126\n",
              "3    0.045761\n",
              "8    0.037557\n",
              "7    0.034640\n",
              "4    0.019690\n",
              "5    0.007475\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GGQgJ7RfUvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with bz2.BZ2File(os.path.join(base_path, dataset, 'lemmatized_wo_stopwords/test.bz2'), \"r\") as f:\n",
        "    df_test = pd.read_json(f, lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGzFlDZBjlM5",
        "colab_type": "text"
      },
      "source": [
        "# Составление ngrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmKNloXijDRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phrases = Phrases(df_train['text'].str.split(), min_count=10, threshold=1)\n",
        "bigram = Phraser(phrases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_invICkf_IA",
        "colab_type": "code",
        "outputId": "bbbe4676-b114-4ee1-e830-57298c305a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "get_bigrams(df_train['text'].str.split().iloc[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stock_split',\n",
              " 'product_inc',\n",
              " 'say_board',\n",
              " 'two_one',\n",
              " 'stock_split',\n",
              " 'common_share',\n",
              " 'shareholder_record',\n",
              " 'company_also',\n",
              " 'say_board',\n",
              " 'shareholder_annual',\n",
              " 'five_mln']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk2Ypi4jk8MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['ngrams'] = df_train['text'].apply(get_bigrams)\n",
        "df_test['ngrams'] = df_test['text'].apply(get_bigrams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jhCDYUekUXX",
        "colab_type": "text"
      },
      "source": [
        "# Сохранение в Vowpal Wabbit формат"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTzyvgfukT68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_vw_format(df_train, os.path.join(dataset, 'train_vw.txt'))\n",
        "to_vw_format(df_test, os.path.join(dataset, 'test_vw.txt'), label_col=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJiupGSykT3e",
        "colab_type": "code",
        "outputId": "170120b8-e117-4b15-c633-7e4defd6c940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "!head r8/train_vw.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 |@default_class champion product ch approve stock split champion product inc say board director approve two one stock split common share shareholder record april company also say board vote recommend shareholder annual meeting april increase authorized capital stock five mln mln share reuter |@ngrams_class stock_split product_inc say_board two_one stock_split common_share shareholder_record company_also say_board shareholder_annual five_mln |@labels_class 1\n",
            "1 |@default_class computer terminal system cpml complete sale computer terminal system inc say complete sale share common stock warrant acquire additional one mln share sedio n v lugano switzerland dlr company say warrant exercisable five year purchase price dlr per share computer terminal say sedio also right buy additional share increase total holding pct computer terminal outstanding common stock certain circumstance involve change control company company say condition occur warrant would exercisable price equal pct common stock market price time exceed dlr per share computer terminal also say sell technolgy rights dot matrix impact technology include future improvement woodco inc houston tex dlr say would continue exclusive worldwide licensee technology woodco company say move part reorganization plan would help pay current operation cost ensure product delivery computer terminal make computer generate label form tag ticket printer terminal reuter |@ngrams_class complete_sale system_inc say_complete share_common acquire_additional n_v company_say five_year purchase_price dlr_per buy_additional outstanding_common control_company company_say common_stock market_price dlr_per also_say say_would company_say would_help |@labels_class 2\n",
            "2 |@default_class cobanco inc cbco year net shr ct vs dlr net vs asset mln vs mln deposit mln vs mln loan mln vs mln note th qtr available year include extraordinary gain tax carry forward dlr five ct per shr reuter |@ngrams_class year_net shr_ct vs_dlr net_vs asset_mln vs_mln mln_vs mln_vs mln_note th_qtr year_include extraordinary_gain five_ct per_shr |@labels_class 1\n",
            "3 |@default_class international inc nd qtr jan oper shr loss two ct vs profit seven ct oper shr profit vs profit rev mln vs mln avg shr mln vs mln six mth oper shr profit nil vs profit ct oper net profit vs profit rev mln vs mln avg shr mln vs mln note per shr calculate payment preferred dividend result exclude credit four ct nine ct qtr six mth vs six ct ct prior period operate loss carryforward reuter |@ngrams_class international_inc nd_qtr oper_shr loss_two ct_vs profit_seven ct_oper shr_profit vs_profit rev_mln vs_mln avg_shr mln_vs mln_six mth_oper shr_profit nil_vs profit_ct oper_net profit_vs profit_rev mln_vs mln_avg shr_mln vs_mln note_per preferred_dividend four_ct nine_ct six_mth vs_six ct_prior loss_carryforward |@labels_class 1\n",
            "4 |@default_class brown forman inc bfd th qtr net shr one dlr vs ct net mln vs mln rev mln vs mln nine mth shr dlr vs dlr net mln vs mln revs billion vs mln reuter |@ngrams_class th_qtr net_shr dlr_vs ct_net mln_vs mln_rev mln_vs mln_nine mth_shr dlr_vs dlr_net mln_vs mln_revs billion_vs mln_reuter |@labels_class 1\n",
            "5 |@default_class dean food df see strong th qtr earnings dean food co expect earnings fourth quarter end may exceed year ago period chairman kenneth dougla tell analyst fiscal fourth quarter food processor report earnings ct share dougla also say year sale exceed billion dlr billion dlr prior year repeat earlier projection third quarter earnings probably slightly last year ct share fall range ct ct share dougla say early project whether anticipated fourth quarter performance would enough exceed prior year overall earnings dlr share dougla say dean experience pct improvement bottom line effect tax reform act alone president howard dean say fiscal company derive benefit various dairy frozen vegetable acquisition ryan milk larsen co dean also say company benefit acquisition late december elgin blender inc west chicago say company major shareholder e b food ltd unite kingdom blender licensing arrangement australia canada brazil japan provide ann entry mcdonald corp mcd year dougla tell analyst reuter |@ngrams_class see_strong th_qtr expect_earnings fourth_quarter year_ago tell_analyst fourth_quarter report_earnings ct_share also_say billion_dlr billion_dlr prior_year third_quarter last_year ct_share ct_share fourth_quarter prior_year earnings_dlr tax_reform also_say tell_analyst |@labels_class 1\n",
            "6 |@default_class brown forman bfdb set stock split payout brown forman inc say board approve three two stock split pct increase company cash dividend company cite improved earnings outlook continue strong cash flow reason raise dividend brown forman say split class class b common share would effective march company say director declare quarterly cash dividend new share class ct payable april one holder record march prior split company pay ct quarterly brown forman today report pct increase third quarter profit mln dlr dlr share seven pct increase sale record mln dlr brown forman say nine month profit decline bit mln dlr dlr share mln dlr dlr share year earlier due second quarter charge ct share restructure beverage operation company say lower corporate tax rate restructuring expect substantially improve brown forman earnings cash flow fiscal reuter |@ngrams_class set_stock inc_say board_approve three_two stock_split pct_increase cash_dividend cash_flow raise_dividend class_b common_share effective_march company_say quarterly_cash share_class ct_payable april_one holder_record today_report pct_increase third_quarter profit_mln dlr_share seven_pct mln_dlr nine_month mln_dlr dlr_share mln_dlr dlr_share year_earlier second_quarter ct_share company_say tax_rate cash_flow |@labels_class 1\n",
            "7 |@default_class esquire radio electronics inc ee th qtr shr profit ct vs profit four ct annual div ct vs ct prior yr net profit vs profit rev vs mth shr profit ct vs loss ct net profit vs loss rev mln vs note annual dividend payable april stockholder record march reuter |@ngrams_class electronics_inc th_qtr shr_profit ct_vs profit_four annual_div ct_vs ct_prior yr_net profit_vs profit_rev mth_shr profit_ct vs_loss ct_net profit_vs loss_rev mln_vs annual_dividend payable_april stockholder_record march_reuter |@labels_class 1\n",
            "8 |@default_class unite presidential corp upco th qtr net shr ct vs ct net vs rev mln vs mln year shr dlr vs dlr net vs rev mln vs mln note result include adjustment dlr ct shr year period improvement result universal life business first estimate reuter |@ngrams_class th_qtr net_shr ct_vs ct_net vs_rev mln_vs mln_year shr_dlr vs_dlr net_vs rev_mln vs_mln note_result dlr_ct year_period |@labels_class 1\n",
            "9 |@default_class owen minor inc obod raise qtly dividend qtly div eight ct vs ct prior pay march record march reuter |@ngrams_class qtly_dividend qtly_div eight_ct vs_ct prior_pay march_record march_reuter |@labels_class 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4IfDSZq_XBs",
        "colab_type": "text"
      },
      "source": [
        "Встроенный парсер библиотеки преобразовал Ваши данные в батчи, обернув их в объект класса BatchVectorizer, который является универсальным типом входных данных для всех методов Python API, прочесть о нём можно тут http://bigartm.readthedocs.org/en/master/python_interface/batches_utils.html. Сами батчи разместились в директории, которую Вы указали как target_folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAbGNzhb_XBv",
        "colab_type": "text"
      },
      "source": [
        "Если же у Вас есть файл в формате Vowpal Wabbit, то воспользуйтесь следующим кодом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83B3T07y_XBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches_path = os.path.join(dataset, 'batches')\n",
        "batch_vectorizer = artm.BatchVectorizer(data_path='r8/train_vw.txt',\n",
        "                                        data_format='vowpal_wabbit',\n",
        "                                        target_folder=batches_path)\n",
        "\n",
        "batches_test_path = os.path.join(dataset, 'batches_test')\n",
        "batch_vectorizer_test = artm.BatchVectorizer(data_path='r8/test_vw.txt',\n",
        "                                        data_format='vowpal_wabbit',\n",
        "                                        target_folder=batches_test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2WeU8je_XCD",
        "colab_type": "text"
      },
      "source": [
        "Следующая цель после создания батчей - создание словаря. Они хранят информацию обо всех уникальных словах в коллекции. Словарь создаётся вне модели, и различными способами (посмотреть их все Вы можете вот тут http://bigartm.readthedocs.org/en/master/python_interface/dictionary.html).\n",
        "Самый базовый вариант - \"собрать\" словарь по директории с батчами. Это нужно делать один раз в самом начале работы с новой коллекцией следующим образом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raFO0aUO_XCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = artm.Dictionary()\n",
        "dictionary.gather(data_path=batches_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8QxQz08afs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary.save_text(os.path.join(dataset, 'vocab.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETNbBgya_XC1",
        "colab_type": "text"
      },
      "source": [
        "Последний момент: все методы создания BatchVectorizer автоматически генерируют словарь по умолчанию, доступ к которому можно получить, написав:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTHiQ1RD_XC3",
        "colab_type": "code",
        "outputId": "021658a8-908b-4722-9c8e-272184ce0073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_vectorizer.dictionary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "artm.Dictionary(name=bf77a61a-7e4d-466e-9ba1-971896744115, num_entries=18541)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfHnv6Nd_XC9",
        "colab_type": "text"
      },
      "source": [
        "Если Вам это, по каким-то причинам, не нужно, при создании BatchVectorizer нужно добавить параметр gather_dictionary=False.\n",
        "Этот флаг будет проигнорирован только в случае data_format равного n\\_wd, поскольку в этом случае другого способа получить словарь не существует."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iLMcLzZ_XFh",
        "colab_type": "text"
      },
      "source": [
        "### Раздел 3: построение мультимодальной тематической модели с регуляризацией и оцениванием качества; метод ARTM.transform()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Vagb-sLH_XFh",
        "colab_type": "text"
      },
      "source": [
        "Теперь перейдём к более сложным случаям. В прошлом разделе было упомянуто понятие модальности. Это нечто, соответствующее каждому слову. Я бы определил это, как вид слова. Бывают слова текста, бывают слова, из которых состоит заголовок. А также слова-имена авторов текста, и даже картинку, если её перекодировать в текст, можно считать набором слов, и слова эти будут типа \"слова из которых состоит картинка\". И таких видов слов можно придумать очень много.\n",
        "\n",
        "Так вот, в BigARTM каждое слово имеет тип модальность. Обозначается она не интуитивно - class_id. Ничего общего с классификацией это не имеет, просто неудачное название, которое уже поздно менять. У каждого слова есть такой class_id, Вы всегда можете задать его сами, либо же библиотека автоматически задаст class_id = '@default_class' (если Вы смотрели внутрь словарей, то, наверняка, видели эту конструкцию). Это - тип обычных слов, тип по умолчанию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-6VazR_P_XFj",
        "colab_type": "text"
      },
      "source": [
        "В большинстве случаев модальности не потребуются, но есть такие ситуации, когда они незаменимы. Например, при классификации документов. Собственно, именно этот пример мы и рассмотрим."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6Hs_y8l_XFl",
        "colab_type": "text"
      },
      "source": [
        "Все данные придётся пересоздавать с учётом наличия модальностей. От Вас потребуется создание файла в формате Vowpal Wabbit, в котором каждая строка - это документ, а каждый документ состоит из обычных слов и слов-меток классов, к которым относится документ. \n",
        "\n",
        "Пример:\n",
        "doc_100500 |@default_class aaa:2 bbb:4 ccc ddd:6 |@labels_class class_1 class_6\n",
        "\n",
        "Всё это подробно описано здесь http://bigartm.readthedocs.org/en/master/formats.html.\n",
        "\n",
        "Теперь проделайте с этим файлом все необходимые манипуляции из вводной части, чтобы получить нужные батчи и словарь."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilQHAn-L_XFm",
        "colab_type": "text"
      },
      "source": [
        "Далее, Вам надо объяснить модели, какие у Вас есть модальности, и какие степени влияния на модель Вы хотите им задать. Степень влияния - это коэффициент модальности $\\tau_m$ (об этом Вы также должны иметь представление). Модель по умолчанию использует только слова модальности '@default_class' и её берёт с $\\tau_m$ = 1.0. Хотите использовать другие модальности и веса - надо задать эти требования в конструкторе модели следующим кодом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPZjr0JQ_XFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = artm.ARTM(num_topics=20, class_ids={'@default_class': 3.0, '@ngrams_class': 3.0, '@labels_class': 1.0}, seed=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-TP9sKX_XFr",
        "colab_type": "text"
      },
      "source": [
        "Итак, мы попросили модель учитывать эти две модальности, причём метки классов сделать в 5 раз более влиятельными, чем обычные слова. Отмечу, что если в вашем файле с данными были ещё модальности, а Вы их тут не отметили - они не будут учтены. Опять же, если Вы отметите в конструкторе модальности, которых нет в данных - случится то же самое.\n",
        "\n",
        "Разумеется, поле class_ids, как и все остальные, является переопределяемым, Вы всегда можете изменить веса модальностей:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-nH69L-_XFw",
        "colab_type": "text"
      },
      "source": [
        "Обновлять веса надо именно так, задавая весь словарь, не надо пытаться обратиться по ключу к отдельной модальности, class_ids обновляется с помощью словаря, но сама словарём не является (словарь - в смысле Python dict)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "zSZwa8CW_XFx",
        "colab_type": "text"
      },
      "source": [
        "При следующем запуске fit_offline() или fit_online() эта информация будет учтена.\n",
        "\n",
        "Теперь к модели надо подключить регуляризаторы и метрики качества. Весь это процесс уже был рассмотрен, за исключением одного момента. Все метрики на матрице $\\Phi$ (а также перплексия) и регуляризаторы $\\Phi$ имеют поля для работы модальностями. Т. е. в этих полях Вы можете определить, с каким модальностями метрика/регуляризатор должна работать, остальные будут проигнорированы (по аналогии с полем topic_names для тем).\n",
        "\n",
        "Поле модальности может быть либо class_id, либо class_ids. Первое - это строка с именем одной модальности, с которой надо работать, второе - список строк с такими модальностями.\n",
        "\n",
        "**Важный момент** со значениями по умолчанию. Для class_id отсутствие заданного Вами значения означает class_id = '@default_class'. Для class_ids отсутствие значения означает использование всех имеющихся в модели модальностей.\n",
        "\n",
        "Посмотреть информацию детально о каждой метрике и каждом регуляризаторе можно по уже данным ранее ссылках http://bigartm.readthedocs.org/en/master/python_interface/regularizers.html и http://bigartm.readthedocs.org/en/master/python_interface/scores.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "s60rN60y_XFy",
        "colab_type": "text"
      },
      "source": [
        "Давайте добавим в модель метрику разреженности $\\Phi$ для модальности меток классов, а также регуляризаторы декорреляции тем для каждой из модальностей, после чего запустим процесс обучения модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRq0hj_NcmL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score', class_id='@labels_class'))\n",
        "\n",
        "model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_def', class_ids=['@default_class']))\n",
        "model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_ngram', class_ids=['@ngrams_class']))\n",
        "model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_lab', class_ids=['@labels_class']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1TF3yLHbB-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.initialize(dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_jwepEU_XFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81kelF1j_XF6",
        "colab_type": "text"
      },
      "source": [
        "Итак, работы по дальнейшей настройке модели, подбору коэффициентов регуляризации, весов модальностей и просмотра метрик остаются Вам. Сейчас же перейдём к использованию обученной модели для классификации тестовых данных.\n",
        "\n",
        "Напомню, что в задаче классификации у Вас есть обучающие данные (коллекция, на которой Вы тренировали модель, где для каждого документа модели известны его метки классов) и данные тестовые, метки которых известны Вам, но не сообщаются модели. Эти скрытые метки модель и должна предсказать, глядя на тестовые документы, а Ваша задача - взять верные ответы и то, что Вам выдала модель, и сравнить, например, посчитав AUC.\n",
        "\n",
        "Подсчёт AUC или ещё каких либо метрик - это Ваше дело, мы этого касаться не будем. А мы займёмся получением для новых документов векторов p(c|d) длиной в количество классов, где каждый элемент - вероятность класса c для данного документа d.\n",
        "\n",
        "Итак, у нас имеется модель. Предполагается, что тестовые документы были убраны в отдельный файл в формате Vowpal Wabbit, на основе которого Вы сумели сгенерировать батчи, которые описываются переменной batch_vectorizer_test (см. вводный раздел). Также предполагается, что сохранили Вы тестовые батчи в отдельную директорию (не в ту, в которую сохранялись обучающие батчи).\n",
        "\n",
        "Ваши тестовые документы не должны содержать информацию о метках классов (а именно: в тестовом файле не должно быть строки '|@labels_class'), также тестовые документы не содержат слов, которых не было в документах обучающих, иначе такие слова будут проигнорированы.\n",
        "\n",
        "Если все эти условия выполнены, можно переходить к использованию ARTM.transform() (об этом написано тут http://bigartm.readthedocs.org/en/master/python_interface/artm.html), который позволяет для всех документов из данного объекта BatchVectorizer получить матрицу вероятностей p(t|d) (т. е. $\\Theta$), либо матрицу p(c|d) для любой указанной модальности.\n",
        "\n",
        "Чтобы получить $\\Theta$ делаем так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO5D1rQV_XF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta_test = model.transform(batch_vectorizer=batch_vectorizer_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTZEQxRr_XF-",
        "colab_type": "text"
      },
      "source": [
        "А чтобы получить p(c|d), запустите такой код:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kwhO7fz_XF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_cd_test = model.transform(batch_vectorizer=batch_vectorizer_test, predict_class_id='@labels_class')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n13yUjVgfph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_cd_test = p_cd_test.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3i4pwTlgQjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = p_cd_test.idxmax(axis=1).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pKE3vmxhhEe",
        "colab_type": "code",
        "outputId": "18ea2326-9ee1-428f-d8cc-efd618e133a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"f1_macro = {f1_score(df_test['label'], y_pred, average='macro')}, \\\n",
        "    accuracy = {accuracy_score(df_test['label'], y_pred)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_macro = 0.13839456319573723,     accuracy = 0.38784833257195067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qzR09Es_XGD",
        "colab_type": "text"
      },
      "source": [
        "Таким образом, Вы получили предсказания модели в pandas.DataFrame. Теперь Вы можете оценить степень качества предсказаний построенной Вами модели любым способом, который Вам необходим."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2G073LCnMgH",
        "colab_type": "text"
      },
      "source": [
        "# Подбор параметров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwrSWm1Qn06m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1OeePI7nO9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(class_ids):\n",
        "    model = artm.ARTM(num_topics=20, class_ids=class_ids, seed=42)\n",
        "    model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score', class_id='@labels_class'))\n",
        "\n",
        "    for class_id in class_ids.keys():\n",
        "        model.regularizers.add(artm.DecorrelatorPhiRegularizer(name=f'decorrelator_phi_{class_id.strip(\"@\")}', \\\n",
        "                                                               class_ids=[class_id]))\n",
        "        \n",
        "    model.initialize(dictionary)\n",
        "    model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)\n",
        "\n",
        "    p_cd_test = model.transform(batch_vectorizer=batch_vectorizer_test, predict_class_id='@labels_class').T\n",
        "    y_pred = p_cd_test.idxmax(axis=1).astype(int)\n",
        "    return f1_score(df_test['label'], y_pred, average='macro')\n",
        "\n",
        "def get_all_combinations(d):\n",
        "    keys = d.keys()\n",
        "    values = (d[key] for key in keys)\n",
        "    combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
        "    return combinations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwYbjdk5olSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    '@default_class': list(range(5)), \n",
        "    '@ngrams_class': [1.0], \n",
        "    '@labels_class': [1.0]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKOK3ifXp9LD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parallel version\n",
        "# pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
        "# param_combinations = get_all_combinations(params)\n",
        "# scores = pool.map(fit_model, param_combinations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1WEfostpSuf",
        "colab_type": "code",
        "outputId": "d3dae3bc-2662-48de-98f4-47c0e6dc3ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_params, best_score = {}, 0\n",
        "for param in tqdm(get_all_combinations(params), position=0):\n",
        "    score = fit_model(param)\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_params = param"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [02:10<00:00, 26.11s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KYCPHMNpSov",
        "colab_type": "code",
        "outputId": "2f0ac52f-b149-4aef-ec9a-7dcc1ae68201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13440685065078858"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4auelSYftbNH",
        "colab_type": "code",
        "outputId": "8e81ea06-aacc-4b15-bf58-7ad445fe15d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_params"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'@default_class': 1, '@labels_class': 1.0, '@ngrams_class': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5icN-kttchm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}