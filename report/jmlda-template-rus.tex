\documentclass[12pt, twoside]{article}
\usepackage{jmlda}
\newcommand{\hdir}{.}

\pgfplotsset{compat=1.15}

\begin{document}

\title
    [Метаобучение тематических моделей классификации] % краткое название; не нужно, если полное название влезает в~колонтитул
    {Метаобучение тематических моделей классификации}
\author
    [А.\,С.~Ватолин] % список авторов (не более трех) для колонтитула; не нужен, если основной список влезает в колонтитул
    {А.\,С.~Ватолин, Ю.\,А.~Сердюк, К.\,В.~Воронцов} % основной список авторов, выводимый в оглавление
    [А.\,С.~Ватолин$^1$, Ю.\,А.~Сердюк$^2$, К.\,В.~Воронцов$^1$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\email
    {vatolinalex@gmail.com; masyes@mail.com;  vokov@forecsys.ru}
% \thanks
    % {Работа выполнена при
    %  %частичной
	%  финансовой поддержке РФФИ, проекты \No\ \No 00-00-00000 и 00-00-00001.}
	% {Задачу поставил: Воронцов~К.\,В.
    %     Консультант: Янина~А.\,О.}
\organization
    {$^1$ Московский физико-технический институт, Москва, Россия}
\abstract
    {Одним из возможных применений вероятностной тематической модели является построение модели не только для текста, но и для имеющихся метаданных (модальностей). Это позволяет более точно определять темы документов, а также предсказывать пропущенные метаданные по имеющимся. Каждая модальность имеет свой вес, который задается вручную и отражает меру влияния данной модальности на темы документов.
    В данной работе исследуются эвристики для начальной инициализации весов модальностей. Получение эвристики позволит
    полностью отказаться от перебора весов модальностей по сетке или же уменьшить количество вариантов перебора.
    Для оценки весов используется мера взаимной информации.
	
	\bigskip
	\noindent
	\textbf{Ключевые слова}: \emph {вероятностное тематическое моделирование; Мультимодальное тематическое моделирование; 
	BigARTM}
}

%данные поля заполняются редакцией журнала
% \doi{10.21469/22233792}
% \receivedRus{01.01.2017}
% \receivedEng{January 01, 2017}

\maketitle
\linenumbers

\section{Введение}
Вероятностное тематическое моделирование - способ построения модели текстовых документов, которая определяет к какой теме
относится каждый документ и какие слова образуют тему. Тематическое моделирование применяется в информационном поиске
\cite{tm_recomedation}, для классификации \cite{rubin2012statistical} и суммаризации текстов \cite{artm_summarization}, 
а также для ранжирования статей \cite{ranktopic}. Одним из продвинутых инструментов, который реализует все из перечисленных выше инструментов, является библиотека BigARTM \cite{vorontsov/artm_book}. Она обладает обширным набором параметров для настройки модели, а также различными резуляризаторами.


В данной статье внимание сконцентрировано на задаче классификации, а именно предлагаются эвристики для оптимальной инициализации весов модальностей в тематической модели. Вводится предположение о том, по статистикам исходной коллекции текстов можно вывести оценку 
Текущие подходы к выбору весов модальности сводятся к двум методам: перебор параметров по сетке или задание константного имперического значения. В работе \cite{vorontsov/blog_search} определение весов осуществляется перебором параметров по сетке методом проб и ошибок. Выбор лучшего набора парамеров осуществлялся по критериям перплекции, разреженности и качества тематического поиска. Также в работе \cite{vorontsov/transactions} предлагается ввести следующее правило: дополнительные модальности не должны увеличивать перпрелксию основной модальности. Введение этого правила не избавляет от перебора по сетке, а лишь изменяет правила выбора лучшего значения для весов. В статье \cite{vorontsov/hierarchical} веса модальностей задаются вручную из соображений важности каждой из модальностей для модели.

Одной из близких к данной задаче является настройка весов регуляризаторов вероятностной тематической модели \cite{vorontsov/artm_book}. Так как задача тематического моделирования является многокритериальной, то одновременно при обучении модели может использоваться несколько регуляризаторов, сбалансированных с помощью весов. В ходе экспериментов было установлено, что весов регуляризаторов зависят от параметров выборки, таких как размер коллекции, мощность словаря, средняя длина документов. Для избавления от необходимости перенастройки весов при изменении парамеров коллекции вводятся относительные коэффициенты регуляризации.

Подбор параметров осуществляется на выборках R8, R52, AG's news, Ohsumed, 20NG, DBPedia, IMDb, Amazon 2, Yelp 5, Sogou News. % TODO: поправить, если список изменится
% После аннотации, но перед первым разделом, располагается введение, включающее в себя
% описание предметной области, обоснование актуальности задачи,
% краткий обзор известных результатов.

\section{Постановка задачи}
Данный документ демонстрирует оформление статьи,
подаваемой в электронную систему подачи статей \url{http://jmlda.org/papers} для публикации в журнале <<Машинное обучение и анализ данных>>.
Более подробные инструкции по~стилевому файлу \texttt{jmlda.sty} и~использованию издательской системы \LaTeXe\
находятся в~документе \texttt{authors-guide.pdf}.
Работу над статьёй удобно начинать с~правки \TeX-файла данного документа.

Обращаем внимание, что данный документ должен быть сохранен в кодировке~\verb'UTF-8 without BOM'.
Для смены кодировки рекомендуется пользоваться текстовыми редакторами \verb'Sublime Text' или \verb'Notepad++'.

\paragraph{Название параграфа}
Разделы и~параграфы, за исключением списков литературы, нумеруются.

\section{Заключение}
Желательно, чтобы этот раздел был, причём он не~должен дословно повторять аннотацию.
Обычно здесь отмечают, каких результатов удалось добиться, какие проблемы остались открытыми.

\bibliographystyle{plain}
\bibliography{literature}

\end{document}
